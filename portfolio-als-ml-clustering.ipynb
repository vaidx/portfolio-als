{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pylab import plot,show\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "import numpy as np\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "import pandas_datareader as dr\n",
    "from math import sqrt\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp500url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "snp1000url = \"https://en.wikipedia.org/wiki/List_of_S%26P_1000_companies\"\n",
    "\n",
    "#scraping wikipedia to fetch S&P 500 stock list\n",
    "snp500_data_table = pd.read_html(snp500url)\n",
    "snp1000_data_table = pd.read_html(snp1000url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Ticker Symbol'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Ticker Symbol'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b208dedfa19b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msnp_500_tickers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msnp500_data_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Symbol'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msnp_1000_tickers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msnp1000_data_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ticker Symbol'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of S&P500 Companies: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnp_500_tickers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of S&P1000 Companies: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnp_1000_tickers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Ticker Symbol'"
     ]
    }
   ],
   "source": [
    "snp_500_tickers = snp500_data_table[0][1:]['Symbol'].tolist()\n",
    "snp_1000_tickers = snp1000_data_table[3]['Ticker Symbol'].tolist()\n",
    "\n",
    "print(\"Number of S&P500 Companies: \" + str(len(snp_500_tickers)))\n",
    "print(\"Number of S&P1000 Companies: \" + str(len(snp_1000_tickers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_cap_tickers = random.sample(snp_500_tickers, 50)\n",
    "mid_and_small_cap_tickers = random.sample(snp_1000_tickers, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_cap = []\n",
    "for ticker in tqdm(large_cap_tickers):\n",
    "    try:\n",
    "        prices = dr.DataReader(ticker,'yahoo','01/01/2017')['Close']\n",
    "        prices = pd.DataFrame(prices)\n",
    "        prices.columns = [ticker]\n",
    "        large_cap.append(prices)\n",
    "    except:\n",
    "        pass\n",
    "    large_df = pd.concat(large_cap,axis=1)\n",
    "large_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mid_cap = []\n",
    "for ticker in tqdm(mid_and_small_cap_tickers):\n",
    "    try:\n",
    "        prices = dr.DataReader(ticker,'yahoo','01/01/2017')['Close']\n",
    "        prices = pd.DataFrame(prices)\n",
    "        prices.columns = [ticker]\n",
    "        small_mid_cap.append(prices)\n",
    "    except:\n",
    "        pass\n",
    "    small_mid_df = pd.concat(small_mid_cap,axis=1)\n",
    "small_mid_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_mid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = pd.merge(large_df, small_mid_df, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns(df):\n",
    "    \n",
    "    lis = prices_df.columns\n",
    "    returns = []\n",
    "    stdev = []\n",
    "    cols = []\n",
    "    srt = np.sqrt(252)\n",
    "    \n",
    "    for col in lis:\n",
    "        ret_lis = df[col].pct_change()\n",
    "        ret_lis = ret_lis.fillna(0)\n",
    "        \n",
    "        rets = ret_lis.mean()*252\n",
    "        returns.append(rets)\n",
    "        \n",
    "        volt = ret_lis.std()*srt\n",
    "        stdev.append(volt)\n",
    "        \n",
    "        cols.append(col)\n",
    "    \n",
    "    dfr = pd.DataFrame({'Company_Name': cols, 'Annual_Returns':returns, 'Volatility':stdev})\n",
    "    dfr = dfr.set_index('Company_Name')\n",
    "    \n",
    "    return dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns = get_returns(prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df.columns.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing X and y\n",
    "\n",
    "a = df_returns[['Annual_Returns','Volatility']]\n",
    "X = np.array(a)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (24, 13.5)\n",
    "cost =[] \n",
    "for i in range(1, 11): \n",
    "    KM = KMeans(n_clusters = i, max_iter = 1000) \n",
    "    KM.fit(X) \n",
    "      \n",
    "    # calculates squared error \n",
    "    # for the clustered points \n",
    "    cost.append(KM.inertia_)      \n",
    "\n",
    "##plot the cost agaisnt K values\n",
    "\n",
    "plt.plot(range(1, 11), cost, color ='g', linewidth ='3') \n",
    "plt.xlabel(\"Value of K\") \n",
    "plt.ylabel(\"Sqaured Error (Cost)\") \n",
    "plt.show() # clear the plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clustering using K = 3\n",
    "\n",
    "km = KMeans(\n",
    "    n_clusters=3, init='random',\n",
    "    n_init=10, max_iter=1000, \n",
    "    tol=1e-04, random_state=0\n",
    ")\n",
    "y_km = km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    X[y_km == 0, 0], X[y_km == 0, 1],\n",
    "    s=50, c='lightgreen',\n",
    "    marker='s', edgecolor='black',\n",
    "    label='cluster 0')\n",
    "\n",
    "plt.scatter(\n",
    "    X[y_km == 1, 0], X[y_km == 1, 1],\n",
    "    s=50, c='orange',\n",
    "    marker='o', edgecolor='black',\n",
    "    label='cluster 1')\n",
    "\n",
    "plt.scatter(\n",
    "    X[y_km == 2, 0], X[y_km == 2, 1],\n",
    "    s=50, c='lightblue',\n",
    "    marker='v', edgecolor='black',\n",
    "    label='cluster 2')\n",
    "\n",
    "\n",
    "# plot the centroids\n",
    "plt.scatter(\n",
    "    km.cluster_centers_[:, 0], km.cluster_centers_[:, 1],\n",
    "    s=250, marker='*',\n",
    "    c='red', edgecolor='black',\n",
    "    label='centroids')\n",
    "\n",
    "plt.xlabel('Returns')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend(scatterpoints=1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns['cluster'] = y_km\n",
    "\n",
    "df_returns.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Cluster 0\n",
    "company_ticker = df_returns.loc[df_returns.cluster==1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LargeCapCluster0 = intersection(company_ticker, large_df.columns)\n",
    "Mid_SmallCapCluster0 = intersection(company_ticker, small_mid_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster0_df = large_df[LargeCapCluster0]\n",
    "Cluster0_df = pd.merge(Cluster0_df, small_mid_df[Mid_SmallCapCluster0], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cluster0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_daily = Cluster0_df.pct_change()\n",
    "\n",
    "monthly_df = Cluster0_df.resample('BMS').first()\n",
    "returns_monthly = monthly_df.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find correlation matrix, i.e. the \"distances\" between each stock\n",
    "#Load relevant packages\n",
    "import datetime\n",
    "from pandas_datareader import data as web\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "corr = Cluster0_df.corr().abs()\n",
    "size = 7\n",
    "fig, ax = plt.subplots(figsize=(size, size))\n",
    "ax.matshow(corr,cmap=cm.get_cmap('coolwarm'), vmin=0,vmax=1)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation='vertical', fontsize=8);\n",
    "plt.yticks(range(len(corr.columns)), corr.columns, fontsize=8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select upper triangle of correlation matrix\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "lower = corr.where(np.tril(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop_upper = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "to_drop_lower = [column for column in lower.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster0_df.drop(Cluster0_df[to_drop], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster0_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating daily and annual returns of the stocks\n",
    "returns_daily = Cluster0_df.pct_change()\n",
    "returns_annual = returns_daily.mean() * 250\n",
    "\n",
    "# get daily and covariance of returns of the stock\n",
    "cov_daily = returns_daily.cov()\n",
    "cov_annual = cov_daily * 250\n",
    "\n",
    "# empty lists to store returns, volatility and weights of imiginary portfolios\n",
    "port_returns = []\n",
    "port_volatility = []\n",
    "sharpe_ratio = []\n",
    "stock_weights = []\n",
    "\n",
    "# set the number of combinations for imaginary portfolios\n",
    "selected = Cluster0_df.columns\n",
    "num_assets = len(selected)\n",
    "num_portfolios = 50000\n",
    "\n",
    "#set random seed for reproduction's sake\n",
    "np.random.seed(101)\n",
    "\n",
    "# populate the empty lists with each portfolios returns,risk and weights\n",
    "for single_portfolio in range(num_portfolios):\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    returns = np.dot(weights, returns_annual)\n",
    "    volatility = np.sqrt(np.dot(weights.T, np.dot(cov_annual, weights)))\n",
    "    \n",
    "    sharpe = returns / volatility\n",
    "    sharpe_ratio.append(sharpe)\n",
    "    port_returns.append(returns)\n",
    "    port_volatility.append(volatility)\n",
    "    stock_weights.append(weights)\n",
    "\n",
    "# a dictionary for Returns and Risk values of each portfolio\n",
    "portfolio = {'Returns': port_returns,\n",
    "             'Volatility': port_volatility,\n",
    "             'Sharpe Ratio': sharpe_ratio}\n",
    "\n",
    "# extend original dictionary to accomodate each ticker and weight in the portfolio\n",
    "for counter,symbol in enumerate(selected):\n",
    "    portfolio[symbol+' Weight'] = [Weight[counter] for Weight in stock_weights]\n",
    "\n",
    "# make a nice dataframe of the extended dictionary\n",
    "df = pd.DataFrame(portfolio)\n",
    "\n",
    "\n",
    "# get better labels for desired arrangement of columns\n",
    "column_order = ['Returns', 'Volatility', 'Sharpe Ratio'] + [stock+' Weight' for stock in selected]\n",
    "\n",
    "# reorder dataframe columns\n",
    "df = df[column_order]\n",
    "\n",
    "# plot frontier, max sharpe & min Volatility values with a scatterplot\n",
    "plt.style.use('seaborn-dark')\n",
    "df.plot.scatter(x='Volatility', y='Returns', c='Sharpe Ratio',\n",
    "                cmap='RdYlBu', edgecolors='black', figsize=(10, 8), grid=True)\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding min Volatility & max sharpe values in the dataframe (df)\n",
    "min_volatility = df['Volatility'].min()\n",
    "max_sharpe = df['Sharpe Ratio'].max()\n",
    "\n",
    "# use the min, max values to locate and create the two special portfolios\n",
    "sharpe_portfolio = df.loc[df['Sharpe Ratio'] == max_sharpe]\n",
    "min_variance_port = df.loc[df['Volatility'] == min_volatility]\n",
    "\n",
    "# plot frontier, max sharpe & min Volatility values with a scatterplot\n",
    "plt.style.use('seaborn-dark')\n",
    "df.plot.scatter(x='Volatility', y='Returns', c='Sharpe Ratio',\n",
    "                cmap='RdYlBu', edgecolors='black', figsize=(10, 8), grid=True)\n",
    "\n",
    "plt.scatter(x=sharpe_portfolio['Volatility'], y=sharpe_portfolio['Returns'], c='red', marker='*', s=200)\n",
    "plt.scatter(x=min_variance_port['Volatility'], y=min_variance_port['Returns'], c='blue', marker='*', s=200 )\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_variance_port"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
